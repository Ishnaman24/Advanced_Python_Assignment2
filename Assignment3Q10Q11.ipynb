{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPPI2yGhbuaLQZIau3ie56",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishnaman24/Advanced_Python_Assignment3/blob/main/Assignment3Q10Q11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c_55kQbinDL"
      },
      "outputs": [],
      "source": [
        "!pip install pytube\n",
        "import os\n",
        "import concurrent.futures\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Function to download a YouTube video given its URL\n",
        "def download_video(url, output_path):\n",
        "    try:\n",
        "        yt = YouTube(url)\n",
        "        video = yt.streams.filter(file_extension='mp4').first()\n",
        "        video.download(output_path)\n",
        "        print(f\"Downloaded: {yt.title}\")\n",
        "        return video.default_filename\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading video: {url}\\n{str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Function to convert video to audio\n",
        "def convert_to_audio(video_path, audio_path):\n",
        "    try:\n",
        "        video = VideoFileClip(video_path)\n",
        "        audio = video.audio\n",
        "        audio.write_audiofile(audio_path)\n",
        "        print(f\"Converted: {video_path} to {audio_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting video to audio: {video_path}\\n{str(e)}\")\n",
        "\n",
        "# Function to process a single video: download and convert to audio\n",
        "def process_video(video_url, output_path):\n",
        "    video_file = download_video(video_url, output_path)\n",
        "    if video_file:\n",
        "        video_path = os.path.join(output_path, video_file)\n",
        "        audio_file = os.path.splitext(video_file)[0] + \".mp3\"\n",
        "        audio_path = os.path.join(output_path, audio_file)\n",
        "        convert_to_audio(video_path, audio_path)\n",
        "\n",
        "# Automated pipeline for downloading and converting videos to audio\n",
        "def automated_pipeline(video_urls, num_threads):\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_path = \"downloaded_videos\"\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    # Create a thread pool executor\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        # Submit the video processing tasks to the executor\n",
        "        results = [executor.submit(process_video, video_url, output_path) for video_url in video_urls]\n",
        "\n",
        "        # Wait for all tasks to complete\n",
        "        concurrent.futures.wait(results)\n",
        "\n",
        "# List of video URLs to download\n",
        "video_urls = [\n",
        "    \"https://www.youtube.com/watch?v=VIDEO_ID_1\",\n",
        "    \"https://www.youtube.com/watch?v=VIDEO_ID_2\",\n",
        "    # Add more video URLs here\n",
        "]\n",
        "\n",
        "# Set the number of threads for parallel processing (adjust as needed)\n",
        "num_threads = 5\n",
        "\n",
        "# Run the automated pipeline\n",
        "automated_pipeline(video_urls, num_threads)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import concurrent.futures\n",
        "from google_images_download import google_images_download\n",
        "from PIL import Image\n",
        "\n",
        "# Function to download images from Google Images\n",
        "def download_images(keyword, output_path, num_images):\n",
        "    response = google_images_download.googleimagesdownload()\n",
        "    arguments = {\"keywords\": keyword, \"limit\": num_images, \"output_directory\": output_path}\n",
        "    paths = response.download(arguments)\n",
        "    print(f\"Downloaded {len(paths[0][keyword])} images for keyword '{keyword}'\")\n",
        "\n",
        "# Function to rescale an image to 50% using PIL\n",
        "def rescale_image(image_path, output_path):\n",
        "    try:\n",
        "        image = Image.open(image_path)\n",
        "        width, height = image.size\n",
        "        new_width = int(width * 0.5)\n",
        "        new_height = int(height * 0.5)\n",
        "        resized_image = image.resize((new_width, new_height))\n",
        "        resized_image.save(output_path)\n",
        "        print(f\"Rescaled: {image_path} to {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error rescaling image: {image_path}\\n{str(e)}\")\n",
        "\n",
        "# Function to process a single image: download and rescale\n",
        "def process_image(keyword, output_path):\n",
        "    download_images(keyword, output_path, 1)\n",
        "    image_file = os.listdir(output_path)[0]\n",
        "    image_path = os.path.join(output_path, image_file)\n",
        "    rescaled_image_file = \"rescaled_\" + image_file\n",
        "    rescaled_image_path = os.path.join(output_path, rescaled_image_file)\n",
        "    rescale_image(image_path, rescaled_image_path)\n",
        "\n",
        "# Automated pipeline for downloading and rescaling images\n",
        "def automated_pipeline(keyword, num_images, num_threads):\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_path = \"downloaded_images\"\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    # Create a thread pool executor\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        # Submit the image processing tasks to the executor\n",
        "        results = [executor.submit(process_image, keyword, output_path) for _ in range(num_images)]\n",
        "\n",
        "        # Wait for all tasks to complete\n",
        "        concurrent.futures.wait(results)\n",
        "\n",
        "# Keyword for image search\n",
        "keyword = \"dog\"\n",
        "\n",
        "# Number of images to download and process\n",
        "num_images = 500\n",
        "\n",
        "# Number of threads for parallel processing (adjust as needed)\n",
        "num_threads = 10\n",
        "\n",
        "# Run the automated pipeline\n",
        "automated_pipeline(keyword, num_images, num_threads)\n"
      ],
      "metadata": {
        "id": "g8lhgrMQjBJX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}